{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Fraud Prediction**\n",
    "\n",
    "## **Problem Statement**\n",
    "\n",
    "ðŸ’¼ **Fraud** merupakan suatu tindakan penipuan pada transaksi keuangan. Transaksi ini bertujuan untuk memperoleh keuntungan dari suatu entitas lain dengan cara ilegal sehingga dapat menyebabkan kerugian. \n",
    "\n",
    "Transaksi fraud sering terjadi di industri perbankan. Beberapa contoh transaksi fraud pada industri perbankan antara lain adalah *pishing, skimming*, penipuan kartu kredit, penipuan pinjaman, dll.\n",
    "\n",
    "Efek negatif dari transaksi fraud adalah adanya kerugian finansial di kedua belah pihak baik customer maupun industri perbankan. Oleh karena itu diperlukan tindakan pencegahan dengan deteksi lebih dini terhadap potensi transaksi fraud. \n",
    "\n",
    "Transaksi fraud dapat dideteksi lebih awal dengan cara membangun model *machine learning* dengan metode klasifikasi. Tugas kita pada project kali ini adalah membuat model klasifikasi untuk mendeteksi transaksi fraud agar dapat dilakukan action plan berikutnya\n",
    "\n",
    "## **Rubrics Penilaian**\n",
    "\n",
    "Untuk menyelesaikan project ini, silahkan mengacu pada rubrics di bawah ini :\n",
    "\n",
    "***Data Preparation***\n",
    "\n",
    "(1 poin) Bagaimana melakukan persiapan data sebelum dilakukan pemodelan.\n",
    "\n",
    "- Metode apa saja yang yang dilakukan dalam proses persiapan data?\n",
    "- Apakah terdapat data yang *missing* atau *duplicate*, bagaimana cara mengatasi data tersebut?\n",
    "\n",
    "(1 poin) Bagaimana cara untuk melakukan *feature engineering* ataupun pemilihan variabel dari data yang tersedia.\n",
    "\n",
    "- Apakah terdapat variable yang dihilangkan? Dan kenapa?\n",
    "- Apakah terdapat variable yang ditambahkan? Dan kenapa?\n",
    "\n",
    "***Exploratory Data Analysis***\n",
    "\n",
    "(2 poin) *Exploratory Data Analysis*\n",
    "\n",
    "- Berikan penjelasan informatif dari visualisasi dan/atau segala jenis hasil eksplorasi Anda.\n",
    "- Bagaimana distribusi data pada setiap variabel?\n",
    "- Apakah terdapat informasi menarik antara variable predictor dengan variable target?\n",
    "\n",
    "***Data Pre-processing and Model Fitting***\n",
    "\n",
    "(1 poin) *Data Pre-processing*\n",
    "\n",
    "- Apakah data categoricalnya akan ditreatement menjadi ordinal atau nominal encoding?\n",
    "\n",
    "(1 poin) *Cross Validation*\n",
    "\n",
    "- Bagaimana pembagian proporsi Data Train & Test?\n",
    "- Apakah proporsi target variable pada data train dibilang cukup stabil? Apakah kita masih harus melakukan *Balancing Data*?\n",
    "\n",
    "(4 poin) Membuat model\n",
    "\n",
    "- Buatlah 2 model yang dapat menjawab pertanyaan bisnis di atas.\n",
    "- Metode evaluasi apa yang akan digunakan?\n",
    "- Apakah modelnya overfit, underfit, just right?\n",
    "- Variable apa yang dirasa cukup penting dalam pembuatan model? Sertakan alasannya.\n",
    "\n",
    "***Prediction Performance***\n",
    "\n",
    "- (1 poin) **Precision** pada dataset **train** mencapai> 80%\n",
    "- (1 poin) **Recall** pada dataset **train** mencapai > 80%\n",
    "- (2 poin) **Precision** pada dataset **test** mencapai > 80%.\n",
    "- (2 poin) **Recall** pada dataset **test** mencapai > 80%.\n",
    "\n",
    "***Conclusion***\n",
    "\n",
    "(2 poin) Tuliskan kesimpulan dari project yang anda kerjakan. \n",
    "\n",
    "- Apakah model sudah dapat melakukan prediksi dengan baik?\n",
    "- Apakah model sudah dapat menjawab pertanyaan bisnis yang ada?\n",
    "- Action plan apa yang dapat dilakukan untuk tindakan preventif transaksi fraud?\n",
    "\n",
    "**Total Poin Capstone Project : 18**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Workflow Pengerjaan**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Data Preparation***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import Library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import recall_score, precision_score, accuracy_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Data dari VSC\n",
    "fraud_data = pd.read_csv('data/fraud_data.csv')\n",
    "fraud_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1 poin) Bagaimana melakukan persiapan data sebelum dilakukan pemodelan.\n",
    "\n",
    "- Metode apa saja yang yang dilakukan dalam proses persiapan data?\n",
    ">Merapikan Kolom dan Mengubah tipe data, \n",
    "- Apakah terdapat data yang *missing* atau *duplicate*, bagaimana cara mengatasi data tersebut?\n",
    ">tidak ada missing value atau duplicate. cara mengatasinya adalah dengan melakukan imputasi dan di drop. sedangkan duplicate dapat di drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pengecekan tipe data\n",
    "fraud_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "## menyalin data merubah tipe data dan melakukan set index\n",
    "fraud_data_copy = fraud_data.copy()\n",
    "\n",
    "fraud_data_copy['type'] = fraud_data_copy['type'].astype(\"category\")\n",
    "\n",
    "fraud_data_copy = fraud_data_copy.set_index('nameOrig')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pengecekan tipe data kembali\n",
    "fraud_data_copy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  melakukan pengecekan data null dan duplikat\n",
    "print(fraud_data_copy.isnull().sum())\n",
    "print(fraud_data_copy.duplicated().sum())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1 poin) Bagaimana cara untuk melakukan *feature engineering* ataupun pemilihan variabel dari data yang tersedia.\n",
    "\n",
    "- Apakah terdapat variable yang dihilangkan? Dan kenapa?\n",
    ">ya. variabel nameDest dihilangkan karena tidak dapat digunakan untuk metode perhitungan\n",
    "- Apakah terdapat variable yang ditambahkan? Dan kenapa?\n",
    ">penambahan variabel type menggunakan pd.get_dummies karena variabel type bersifat nominal sehingga dapat harus dilakukan encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# penghapusan kolom yang tidak diperlukan da\n",
    "fraud_data_copy = fraud_data_copy.drop(columns='nameDest')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Exploratory Data Analysis***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2 poin) *Exploratory Data Analysis*\n",
    "\n",
    "- Berikan penjelasan informatif dari visualisasi dan/atau segala jenis hasil eksplorasi Anda.\n",
    "> 1. oldbalancedest di dominasi data  0. ini menunjukan kebanyakan transaksi tertuju pada rekening kosong\n",
    "> 2. terdapat amount 0. yang berarti terdapat transaksi yang tidak valid\n",
    "> 3. data fraud hanya dilakukan menggunakan type CASH_OUT dan TRANSFER\n",
    "> 4. korelasi yang paling tinggi terhadap fraud adalah data amount\n",
    "\n",
    "- Bagaimana distribusi data pada setiap variabel?\n",
    "> 1. pada data ini terdapat beberapa data yang memiliki kesamaan dalam distribusi datanya terlebih pada kolom oldbalanceDest dan newBalanceDest\n",
    "> 2. data berkumpul di luar kotak whiskers. ini menandakan banyak data yang outlier\n",
    "\n",
    "- Apakah terdapat informasi menarik antara variable predictor dengan variable target?\n",
    "> untuk menjawab hal ini, saya menggunakan corr() untuk menghitung koefisiensi korelasi antar variaber predictor dan variabel target\n",
    "> - dari pengecekan korelasi mendapatkan hasil bahwa variabel AMOUNT dan TYPE_CASHOUT lah yang memiliki korelasi yang paling kuat dari data target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pengecekan menggunakan describe\n",
    "fraud_data_copy[fraud_data_copy['isFraud']==1].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pengecekan sebaran data\n",
    "pd.crosstab(index= fraud_data_copy['type'], columns= fraud_data_copy['isFraud'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cek korelasi antar variabel predictor dengan target\n",
    "fraud_enc_real.corr()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Data Pre-processing and Model Fitting***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1 poin) *Data Pre-processing*\n",
    "\n",
    "- Apakah data categoricalnya akan ditreatement menjadi ordinal atau nominal encoding?\n",
    ">iya. melakukan encoding pada data variabel \"type\" menjadi nominal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "## melakukan encoding pada variabel type menjadi nominal\n",
    "fraud_enc = pd.get_dummies(data = fraud_data_copy, \n",
    "                             columns = ['type'],\n",
    "                             drop_first = True,\n",
    "                             dtype =float)\n",
    "fraud_enc_real = fraud_enc.copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1 poin) *Cross Validation*\n",
    "\n",
    "- Bagaimana pembagian proporsi Data Train & Test?\n",
    "> pembagian menggunakan train_test_split dengan pembagian 70% data training dan 30% data test\n",
    "- Apakah proporsi target variable pada data train dibilang cukup stabil? Apakah kita masih harus melakukan *Balancing Data*?\n",
    "> porposi tidak seimbang antara data fraud dengan tidak fraud yaitu 2793 data fraud, dan 4207 data tidak fraud. oleh karena itu dibutuhkan metode downsampling, oversampling ataupun smote untuk melakukan balancing data. dan didalam model ini saya akan menggunakan smote untuk melakukan balancing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# melakukan pembagian antara target dan prediktor\n",
    "import statsmodels.api as sm\n",
    "\n",
    "target = fraud_enc['isFraud']\n",
    "\n",
    "prediktor = fraud_enc.drop(columns= 'isFraud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# melakukan pembagian data train dan test \n",
    "X_train, X_test, y_train, y_test = train_test_split(prediktor, \n",
    "                                                    target, \n",
    "                                                    test_size = 0.3, \n",
    "                                                    random_state = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cek proporsi data\n",
    "pd.crosstab(index = y_train, columns = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# melakukan balancing data menggunakan smote sampling\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "\n",
    "smote_nc = SMOTENC(categorical_features=[3, 4, 5, 6], random_state=0)\n",
    "X_train_smote, y_train_smote = smote_nc.fit_resample(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4 poin) Membuat model\n",
    "\n",
    "- Buatlah 2 model yang dapat menjawab pertanyaan bisnis di atas.\n",
    "> saya menggunakan 2 model yaitu decision tree dan random forest\n",
    "- Metode evaluasi apa yang akan digunakan?\n",
    "> menggunakan precision dan recall. selain itu saya juga menggunakan oob_score untuk menhitung akurasi dari random forest \n",
    "- Apakah modelnya overfit, underfit, just right?\n",
    "> menggunakan decision tree, hasilnya menjadi overfit karena itu juga adalah kelemahan dari model tersebut. oleh karena itu saya melakukan pruning untuk menghadapi hal tersebut.\n",
    "> sedangkan menggunakan random forest hasilnya sudah optimal\n",
    "- Variable apa yang dirasa cukup penting dalam pembuatan model? Sertakan alasannya.\n",
    ">untuk menjawab hal ini, saya menggunakan metode feature_importan dari 2 model yang dibuat untuk mengetahui variabel yang memiliki pengaruh yang signifikan\n",
    "> - feature_importances_ Decision Tree = menjelaskan bahwa variabel OLDBALANCE, AMOUNT, TYPE_PAYMENT lah yang paling berpengaruh dari model tersebut\n",
    "> - feature_importances_ Random Forest = menjelaskan bahwa variabel AMOUNT, TYPE_TRANSFER, NEW_BALANCE lah yang paling berpengaruh dari model tersebut\n",
    "> \n",
    ">kesimpulan yang bisa diambil adalah bahwa variabel AMOUNT lah yang paling penting dalam pembuatan model ini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# membuat 2 model yaitu model Decision Tree dan Random Forest\n",
    "\n",
    "# - Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "DT_smote = DecisionTreeClassifier(criterion='entropy', random_state=10)\n",
    "DT_smote = DT_smote.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# - Decision Tree + pruning\n",
    "DT_tuning = DecisionTreeClassifier(\n",
    "    max_depth=5,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=5,\n",
    "    max_leaf_nodes=None,\n",
    "    random_state=123)\n",
    "\n",
    "DT_tuning.fit(X_train_smote, y_train_smote)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "Model_rf = RandomForestClassifier(random_state=500, \n",
    "                                   oob_score = True, \n",
    "                                   n_estimators= 500, #jumlah dt\n",
    "                                   max_depth=50,\n",
    "                                   min_samples_split=10,\n",
    "                                   min_samples_leaf=5,\n",
    "                                   max_leaf_nodes=None)\n",
    "\n",
    "Model_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cek variabel yang penting dari decesion tree\n",
    "import plotly.express as px\n",
    "var_importance = \\\n",
    "pd.Series(\n",
    "    DT_smote.feature_importances_, \n",
    "    index=X_train_smote.columns \n",
    "    ).sort_values(ascending=False).tail(10) \n",
    "\n",
    "px.bar(var_importance)\n",
    "# oldbalance, amount, type_payment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# cek variabel yang penting dari random forest\n",
    "\n",
    "Model_rf.feature_importances_\n",
    "import plotly.express as px\n",
    "var_importance = \\\n",
    "pd.Series(\n",
    "    Model_rf.feature_importances_, \n",
    "    index=X_train.columns \n",
    "    ).sort_values(ascending=False).tail(10) \n",
    "\n",
    "px.bar(var_importance)\n",
    "# amount, type_transfer, new_balance, old_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pengecekan oob_score untuk random forest\n",
    "Model_rf.oob_score_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Prediction Performance***\n",
    "\n",
    "- (1 poin) **Precision** pada dataset **train** mencapai> 80%"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- (1 poin) **Recall** pada dataset **train** mencapai > 80%"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- (2 poin) **Precision** pada dataset **test** mencapai > 80%."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- (2 poin) **Recall** pada dataset **test** mencapai > 80%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediksi DecisionTree terhadap data test\n",
    "y_pred_dt_test = DT_smote.predict(X_test)\n",
    "\n",
    "print(f'dt test Recall score: {recall_score(y_test, y_pred_dt_test)}')\n",
    "print(f'dt test Precision score: {precision_score(y_test, y_pred_dt_test)}')\n",
    "\n",
    "# Prediksi DecisionTree terhadap data train\n",
    "ytrain_pred_dt_train = DT_smote.predict(X_train_smote)\n",
    "\n",
    "print(f'dt train Recall score: {recall_score(y_train_smote, ytrain_pred_dt_train)}')\n",
    "print(f'dt train Precision score: {precision_score(y_train_smote, ytrain_pred_dt_train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediksi DecisionTree yang sudah di pruning terhadap data test\n",
    "y_pred_tuning_test = DT_tuning.predict(X_test)\n",
    "\n",
    "print(f'dt test Recall score: {recall_score(y_test, y_pred_tuning_test)}')\n",
    "print(f'dt test Precision score: {precision_score(y_test, y_pred_tuning_test)}')\n",
    "\n",
    "# Prediksi DecisionTree terhadap data train\n",
    "ytrain_pred_dt_train = DT_tuning.predict(X_train_smote)\n",
    "\n",
    "print(f'dt train Recall score: {recall_score(y_train_smote, ytrain_pred_dt_train)}')\n",
    "print(f'dt train Precision score: {precision_score(y_train_smote, ytrain_pred_dt_train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediksi Randomforest terhadap data test\n",
    "\n",
    "pred_test_rf = Model_rf.predict(X_test)\n",
    "\n",
    "print(f'RF test Recall score: {recall_score(y_test, pred_test_rf)}')\n",
    "print(f'RF test Precision score: {precision_score(y_test, pred_test_rf)}')\n",
    "\n",
    "\n",
    "# Prediksi Randomforest terhadap data train\n",
    "\n",
    "pred_train_rf = Model_rf.predict(X_train)\n",
    "\n",
    "print(f'RF train Recall score: {recall_score(y_train, pred_train_rf)}')\n",
    "print(f'RF train Precision score: {precision_score(y_train, pred_train_rf)}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Conclusion***\n",
    "\n",
    "(2 poin) Tuliskan kesimpulan dari project yang anda kerjakan. \n",
    "\n",
    "- Apakah model sudah dapat melakukan prediksi dengan baik? \n",
    "> iya. model sudah dapat melakukan prediksi degan baik. menggunakan decision tree maupun random forest. bisa dilihat dari nilai recall dan precision serta oob score yang tinggi diatas 80%. namun untuk kasus decision tree, model melakukan prediksi yang overfit sehingga perlu di pruning\n",
    "- Apakah model sudah dapat menjawab pertanyaan bisnis yang ada?\n",
    ">saya rasa iya, karena model sudah dapat melakukan prediksi yang tinggi terhadap transaksi fraud\n",
    "- Action plan apa yang dapat dilakukan untuk tindakan preventif transaksi fraud?\n",
    "> menurut saya. dari hasil model diatas telah melakukan prediksi yang baik. sehingga model diatas sudah dapat diimplementasikan kedalam production seperti sebuah sistem deteksi transaksi fraud otomatis atau sistem monitoring real-time. namun ada baiknya agar selalu melakukan evaluasi Secara Berkala dari model mengenai tingkat performanya"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bri_py1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
